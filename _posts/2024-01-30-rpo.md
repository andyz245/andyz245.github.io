---
layout: post
title:  "Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks"
date:   2024-01-30
image: /images/rpo.png
categories: research
author: "Andy Zhou"
authors: "<strong>Andy Zhou</strong>, Bo Li, Haohan Wang"
venue: "arXiv"
arxiv: https://arxiv.org/abs/2401.17263
code: https://github.com/andyz245/rpo/tree/main
website: 
slides: /pdfs/rpo.pdf
---
We propose a defense objective for defending LLMs against jailbreaking and an algorithm to generate trigger tokens that enforce harmless behavior, improving robustness across jailbreaks and models. 
