---
layout: post
title:  "Jailbreaking Large Language Models Against Moderation Guardrails via Cipher Characters"
date:   2024-09-11
image: /images/jam.png
categories: research
author: "Andy Zhou"
authors: "Haibo Jin, <strong>Andy Zhou</strong>, Joe D. Menke, Haohan Wang"
venue: "NeurIPS 2024 Spotlight"
arxiv: https://arxiv.org/abs/2405.20413
website:
---
We propose an attack on moderation guardrails that use cipher characters to detect harmful content and a benchmark for evaluating LLM guardrails.
